import streamlit as st
from PIL import Image
Image.MAX_IMAGE_PIXELS = None
from io import BytesIO
import os
from transformers import ViTFeatureExtractor, ViTForImageClassification
from sentence_transformers import SentenceTransformer
import torch
import base64
import openai

# LangChain & LLM
from langchain_community.vectorstores.faiss import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.documents import Document
from Bio import Entrez

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "qa_history" not in st.session_state:
    st.session_state.qa_history = []

# ì´ë¯¸ì§€ ìœ ì‚¬ ë…¼ë¬¸ ì°¾ê¸°
def find_similar_papers_from_image(image_bytes):
    image = Image.open(BytesIO(image_bytes))
    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')
    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
    inputs = feature_extractor(images=image, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
    return [
        Document(page_content="Ovarian cancer tissue with high mitotic index...", metadata={"pmid": "12345678", "source": "pubmed"}),
        Document(page_content="Study on serous subtype of ovarian carcinoma...", metadata={"pmid": "87654321", "source": "pubmed"})
    ]

# PubMed ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„± (LLM í™œìš©)
def generate_pubmed_query_from_question(question: str) -> str:
    query_prompt = PromptTemplate(
        input_variables=["question"],
        template="""
        ì•„ë˜ ì„¤ëª…ì€ AIê°€ ì¡°ì§ ë³‘ë¦¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
        ì´ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ PubMed ê²€ìƒ‰ì„ ìœ„í•œ Boolean ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.

        - í•µì‹¬ ì§ˆë³‘ëª…, ì¡°ì§ëª…, ì—¼ìƒ‰ë²•(H&E ë“±), ë³‘ë¦¬ ìš©ì–´ ì¤‘ì‹¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì„¸ìš”.
        - Boolean ì—°ì‚°ì (AND, OR)ì™€ ê´„í˜¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - í‚¤ì›Œë“œëŠ” 3~6ê°œ ì‚¬ì´ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
        - ì˜ˆì‹œ: (histology OR tissue) AND (H&E OR staining) AND (diagnosis OR cancer)

        ì„¤ëª…:
        {question}

        ì¶œë ¥ í˜•ì‹: PubMed Boolean Query 
        """
    )
    prompt_str = query_prompt.format(question=question)
    return llm.invoke(prompt_str).content.strip()

# PubMed ë…¼ë¬¸ ê²€ìƒ‰
def search_pubmed(question: str, max_results: int = 3):
    Entrez.email = "yejijin98@gmail.com"
    query = generate_pubmed_query_from_question(question)
    handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results)
    record = Entrez.read(handle)
    ids = record["IdList"]

    summaries = []
    seen_pmids = set()
    for pmid in ids:
        if pmid in seen_pmids:
            continue
        seen_pmids.add(pmid)

        summary = Entrez.esummary(db="pubmed", id=pmid, retmode="xml")
        summary_record = Entrez.read(summary)
        if not summary_record or not isinstance(summary_record[0], dict):
            continue
        title = summary_record[0].get("Title", "[ì œëª© ì—†ìŒ]")
        pubdate = summary_record[0].get("PubDate", "")                      # PubMedëŠ” 'PubDate' í‚¤ë¥¼ ì‚¬ìš©
        year = pubdate.split()[0] if pubdate else ""                        # ì•ˆì „í•˜ê²Œ ì—°ë„ë§Œ ì¶”ì¶œ
        authors = summary_record[0].get("AuthorList", [])                   # authors â†’ AuthorList
        author_str = ", ".join(authors[:2]) + (" et al." if len(authors) > 2 else "")


        fetch = Entrez.efetch(db="pubmed", id=pmid, rettype="abstract", retmode="text")
        abstract = fetch.read()
        if not abstract:
            continue

        summaries.append(Document(
            page_content=abstract,
            metadata={"pmid": pmid, "title": title, "year": year, "authors": author_str, "source": "pubmed"}
        ))
    return summaries

prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
    
ë‹¹ì‹ ì€ ë‚œì†Œì•” ì¡°ì§ ë³‘ë¦¬ ì´ë¯¸ì§€ì™€ ê´€ë ¨ëœ AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ë…¼ë¬¸ì—ì„œ ë°œì·Œí•œ ë‚´ìš©ì…ë‹ˆë‹¤:
---------------------
{context}
---------------------

ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
ì§ˆë¬¸: {question}
"""
)

# Streamlit UI
st.set_page_config(page_title="Ovarian Cancer RAG", layout="wide")

st.sidebar.title("ğŸ” OpenAI API KEY ì…ë ¥")
user_api_key = st.sidebar.text_input("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if user_api_key:
    st.session_state["user_api_key"] = user_api_key
openai.api_key = st.session_state.get("user_api_key", "")

st.title("ğŸ”¬ ë‚œì†Œì•” ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸")

question = st.text_input("í…ìŠ¤íŠ¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆì‹œ) What are the subtypes of ovarian cancer?")

uploaded_file = st.file_uploader("ì¡°ì§ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒ)", type=["png", "jpg", "jpeg"])

if st.button("ë¶„ì„ ì‹¤í–‰"):
    # LLM ì„¤ì •
    llm = ChatOpenAI(model="gpt-4", temperature=0, api_key=st.session_state.get("user_api_key", ""))
    embeddings = HuggingFaceEmbeddings(
    model_name="dmis-lab/biobert-base-cased-v1.1",
    model_kwargs={}
    )
        
    if uploaded_file is not None:
        # âœ… ì´ë¯¸ì§€ ë¶„ì„ ë¸”ë¡
        image_bytes = uploaded_file.read()
        image = Image.open(BytesIO(image_bytes))
        st.image(image, caption="ì—…ë¡œë“œëœ ì¡°ì§ ì´ë¯¸ì§€", use_container_width=True)

        base64_str = base64.b64encode(image_bytes).decode("utf-8")
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_str}"}}
                ],
            }
        ]

        try:
            with st.spinner("GPT-4o ë¶„ì„ ì¤‘..."):
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    max_tokens=500
                )
            if not response.choices:
                raise ValueError("GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

            ai_answer = response.choices[0].message.content
            st.subheader("AI ë‹µë³€")
            st.write(ai_answer)

            search_query = generate_pubmed_query_from_question(ai_answer)
            related_papers = search_pubmed(search_query, max_results=3)

            st.subheader("ğŸ“„ ê´€ë ¨ ë…¼ë¬¸")
            if not related_papers:
                st.markdown("ğŸ” ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for doc in related_papers:
                    title = doc.metadata.get("title", "[ì œëª© ì—†ìŒ]")
                    year = doc.metadata.get("year", "")
                    authors = doc.metadata.get("authors", "")
                    pmid = doc.metadata.get("pmid", "")
                    url = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/" if pmid else ""
                    st.markdown(f"- [{title}]({url}) ({year}, {authors})" if url else f"- {title} ({year}, {authors})")

            with st.expander("ë‹µë³€ ê´€ë ¨ ë…¼ë¬¸"):
                    docs = find_similar_papers_from_image(image_bytes)
                    splitter = CharacterTextSplitter(chunk_size=5000, chunk_overlap=200)
                    


        except Exception as e:
            st.error(f"âŒ GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}")

    else:
        # âœ… í…ìŠ¤íŠ¸ ê¸°ë°˜ Q&A ë¸”ë¡        
        docs = search_pubmed(question=question)
        splitter = CharacterTextSplitter(chunk_size=5000, chunk_overlap=200)
        chunks = splitter.split_documents(docs)
        vector_db = FAISS.from_documents(chunks, embeddings)
        retriever = vector_db.as_retriever(search_kwargs={"k": 3})

        rag_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            chain_type="stuff",
            chain_type_kwargs={"prompt": prompt_template},
            return_source_documents=True
        )
        result = rag_chain.invoke({"query": question})

        st.session_state.qa_history.insert(0, {
            "question": question,
            "answer": result["result"],
            "sources": result["source_documents"]
        })

        st.subheader("ğŸ–ï¸ ìš”ì•½ ë‹µë³€")
        st.write(result["result"])
        st.subheader("ğŸ“„ ë…¼ë¬¸ ì¶œì²˜")

        seen_pmids = set()
        for doc in result["source_documents"]:
            pmid = doc.metadata.get("pmid")
            if pmid in seen_pmids:
                continue
            seen_pmids.add(pmid)

            title = doc.metadata.get("title", "[ì œëª© ì—†ìŒ]")
            year = doc.metadata.get("year", "")
            authors = doc.metadata.get("authors", "")
            url = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/" if pmid else ""

            st.markdown(f"- [{title}]({url}) ({year}, {authors})" if url else f"- {title} ({year}, {authors})")


# âœ… í•˜ë‹¨ì— ì´ì „ Q&A í‘œì‹œ (ê°€ì¥ ìµœê·¼ ê²ƒì€ ì œì™¸)
if len(st.session_state.qa_history) > 1:
    st.markdown("## ğŸ“š ì´ì „ Q&A ê¸°ë¡")

    for idx, entry in enumerate(st.session_state.qa_history[1:]):
        with st.expander(f"Q{len(st.session_state.qa_history) - idx - 1}: {entry['question']}"):
            st.markdown("**ğŸ–ï¸ ìš”ì•½ ë‹µë³€**")
            st.write(entry["answer"])
            st.markdown("**ğŸ“„ ì¶œì²˜**")
            for doc in entry["sources"]:
                source = doc.metadata.get("source", "pubmed")
                title = doc.metadata.get("title", "[ì œëª© ì—†ìŒ]")
                year = doc.metadata.get("year", "")
                authors = doc.metadata.get("authors", "")
                doi = doc.metadata.get("doi")
                pmid = doc.metadata.get("pmid")
                pmcid = doc.metadata.get("pmcid")

                if source == "pubmed" and pmid:
                    url = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
                elif source == "crossref" and doi:
                    url = f"https://doi.org/{doi}"
                elif source == "europepmc":
                    if pmcid:
                        url = f"https://europepmc.org/article/PMC/{pmcid}"
                    elif pmid:
                        url = f"https://europepmc.org/article/MED/{pmid}"
                    elif doi:
                        url = f"https://europepmc.org/article/DOI/{doi}"
                    else:
                        url = ""
                else:
                    url = ""

                if url:
                    st.markdown(f"- [{title}]({url}) ({year}, {authors})")
                else:
                    st.markdown(f"- {title} ({year}, {authors})")

# ğŸ§¼ ê¸°ë¡ ì´ˆê¸°í™”
if st.button("ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.qa_history = []
    st.rerun()


